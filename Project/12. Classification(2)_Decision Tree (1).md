# 2022-1 í•™ê¸° ë°ì´í„°ë§ˆì´ë‹ í”„ë¡œì íŠ¸_(11)  

ğŸ ì €ë²ˆ ê¸€ì— ì´ì–´ ì´ë²ˆ ê¸€ì—ì„œëŠ” Decisioin Treeë¥¼ í†µí•´ ê° ë°ì´í„°í”„ë ˆì„ì˜ accuracyë¥¼ ë¹„êµí•´ë³´ì.<br>  

ğŸ ë¨¼ì € ì‚¬ìš©í•  ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ë„ë¡ í•˜ì.<br>  

***  

ğŸ“Œ ì „ì²˜ë¦¬í•œ ë°ì´í„°  
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/187910972-0200d35a-827d-46e5-90d6-a2c89a466825.png" width="800" /></p>  

***  

ğŸ“Œ PCA ë°ì´í„°í”„ë ˆì„  
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/182032289-57f4c876-f37d-4cb3-9575-0af0ec376a15.png" width="700" /></p>  

***  

## 1. Original Data  

ğŸ ë¨¼ì € ê°€ì ¸ì˜¨ ë°ì´í„°ì˜ targetì„ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½í•´ì£¼ì.  

```py
cardio.target_rand = cardio['cardio'].copy()
cardio.target_rand[cardio.target_rand==0] = 'N'
cardio.target_rand[cardio.target_rand==1] = 'Y'  
```  

ğŸ ì´ì œ ì•ì„  ì—°ê´€ê´€ê³„ ë¶„ì„ì—ì„œ ì¶”ì¶œí•œ attributeë“¤ì„ ê°€ì§€ê³  ê°ê°ì˜ ê²½ìš°ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“¤ì–´ ì¤„ ê²ƒì´ë‹¤.  

```py
# 1. ì „ì²´ feature ì‚¬ìš©
cardio_1_feat = cardio.drop(['cardio'], axis = 1).copy()  

# 2. [aphi, aplo, cholesterol, BMI]
cardio_2_feat = cardio.drop(['cardio','age','gender','gluc','smoke','alco','active'], axis = 1).copy()

#3. [age, aphi, aplo, cholesterol, BMI]
cardio_3_feat = cardio.drop(['cardio','gender','gluc','smoke','alco','active'], axis = 1).copy() 

#4. [age, aphi, aplo, cholesterol, gluc, BMI]
cardio_4_feat = cardio.drop(['cardio','gender','smoke','alco','active'], axis = 1).copy()

#5. [age, aphi, aplo, cholesterol, gluc, BMI, active]
cardio_5_feat = cardio.drop(['cardio','gender','alco','smoke'], axis = 1).copy() 

#6. [aphi, aplo, cholesterol, gluc, BMI]
cardio_6_feat = cardio.drop(['cardio','gender','alco','smoke','age','active'], axis = 1).copy() 
```  

ğŸ ê° ë°ì´í„°ê°€ ê°€ì§€ê³  ìˆëŠ” attributeë“¤ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì¼ì¼ì´ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²Œ ìƒë‹¨íˆ ë²ˆê±°ë¡œìš´ ì¼ì´ë¼ê³  ìƒê°í–ˆë‹¤. ë”°ë¼ì„œ ì´ë¥¼ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì˜€ë‹¤.  

ğŸ ì¶”ì¶œí•œ attribute ë§Œìœ¼ë¡œ êµ¬ì„±ëœ ë°ì´í„°í”„ë ˆì„ê³¼ ê²°ì •íŠ¸ë¦¬ì˜ ê¹Šì´ë¥¼ ì¸ìˆ˜ë¡œ ë°›ì•„ train setê³¼ test setì˜ accuracyë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ì£¼ì—ˆë‹¤.  

```py
def predict_accuracy(features, depth):
    x_train, x_test, y_train, y_test = train_test_split(features, cardio.target_rand, test_size=0.3, random_state=1)
   
   # ë°ì´í„° í‘œì¤€í™” ì‘ì—…
    sc = StandardScaler()
    sc.fit(x_train)

    # í‘œì¤€í™”ëœ ë°ì´í„°ì…‹
    x_train_std = sc.transform(x_train)
    x_test_std = sc.transform(x_test)

     # ì¢…ì†ë³€ìˆ˜ê°€ í˜„ì¬ ë²”ì£¼í˜•
    clf_train = tree.DecisionTreeClassifier(criterion="entropy",max_depth=depth)
    clf_train = clf_train.fit(x_train,y_train)
    
    # ì¢…ì†ë³€ìˆ˜ê°€ í˜„ì¬ ë²”ì£¼í˜•
    clf_test = tree.DecisionTreeClassifier(criterion="entropy",max_depth=depth)
    clf_test = clf_test.fit(x_train,y_train)

    y_pred_tr_train = clf_train.predict(x_train)
    y_pred_tr_test = clf_test.predict(x_test)
    
    return clf_train, accuracy_score(y_train, y_pred_tr_train), clf_test, accuracy_score(y_test, y_pred_tr_test)
```  

ğŸ ì´ í•¨ìˆ˜ë¥¼ ê°€ì§€ê³  accracyë¥¼ ê³„ì‚°í•´ë³´ì.  

***  

### ğŸš© 1.1. max_depth = None ê²°ê³¼í•´ì„  

```py
# max_depth = None ì¸ ê²½ìš°ì˜ train set accuracyì™€ test set accuracy

print('Case 1 train Accuracy: %.5f' % predict_accuracy(cardio_1_feat, None)[1])
print('Case 1 test Accuracy: %.5f' % predict_accuracy(cardio_1_feat, None)[3], '\n')

print('Case 2 train Accuracy: %.5f' % predict_accuracy(cardio_2_feat, None)[1])
print('Case 2 test Accuracy: %.5f' % predict_accuracy(cardio_2_feat, None)[3], '\n')

print('Case 3 train Accuracy: %.5f' % predict_accuracy(cardio_3_feat, None)[1])
print('Case 3 test Accuracy: %.5f' % predict_accuracy(cardio_3_feat, None)[3], '\n')

print('Case 4 train Accuracy: %.5f' % predict_accuracy(cardio_4_feat, None)[1])
print('Case 4 test Accuracy: %.5f' % predict_accuracy(cardio_4_feat, None)[3], '\n')

print('Case 5 train Accuracy: %.5f' % predict_accuracy(cardio_5_feat, None)[1])
print('Case 5 test Accuracy: %.5f' % predict_accuracy(cardio_5_feat, None)[3], '\n')

print('Case 6 train Accuracy: %.5f' % predict_accuracy(cardio_6_feat, None)[1])
print('Case 6 test Accuracy: %.5f' % predict_accuracy(cardio_6_feat, None)[3], '\n')
```
```
>>
Case 1 train Accuracy: 0.97181
Case 1 test Accuracy: 0.64212 

Case 2 train Accuracy: 0.82638
Case 2 test Accuracy: 0.65860 

Case 3 train Accuracy: 0.94109
Case 3 test Accuracy: 0.64300 

Case 4 train Accuracy: 0.94673
Case 4 test Accuracy: 0.64134 

Case 5 train Accuracy: 0.95736
Case 5 test Accuracy: 0.64382 

Case 6 train Accuracy: 0.84334
Case 6 test Accuracy: 0.65659 
```  

ğŸ“Œ train setì˜ accuracyì™€ test setì˜ accuracyì˜ ì°¨ì´ê°€ í¼ : ì˜¤ë²„í”¼íŒ…ì´ ì¼ì–´ë‚¬ë‹¤ê³  ì˜ˆì¸¡í•  ìˆ˜ ìˆìŒ  

ğŸ“Œ Pruningì„ í†µí•œ ì˜¤ë²„í”¼íŒ… ì¡°ì •ì˜ í•„ìš”ì„±  

***  

### ğŸš© 1.2. 1.1.2  max_depth = 5 ê²°ê³¼í•´ì„  

```py
# max_depth = 5 ì¸ ê²½ìš°ì˜ train set accuracyì™€ test set accuracy

print('Case 1 train Accuracy: %.5f' % predict_accuracy(cardio_1_feat, 5)[1])
print('Case 1 test Accuracy: %.5f' % predict_accuracy(cardio_1_feat, 5)[3], '\n')

print('Case 2 train Accuracy: %.5f' % predict_accuracy(cardio_2_feat, 5)[1])
print('Case 2 test Accuracy: %.5f' % predict_accuracy(cardio_2_feat, 5)[3], '\n')

print('Case 3 train Accuracy: %.5f' % predict_accuracy(cardio_3_feat, 5)[1])
print('Case 3 test Accuracy: %.5f' % predict_accuracy(cardio_3_feat, 5)[3], '\n')

print('Case 4 train Accuracy: %.5f' % predict_accuracy(cardio_4_feat, 5)[1])
print('Case 4 test Accuracy: %.5f' % predict_accuracy(cardio_4_feat, 5)[3], '\n')

print('Case 5 train Accuracy: %.5f' % predict_accuracy(cardio_5_feat, 5)[1])
print('Case 5 test Accuracy: %.5f' % predict_accuracy(cardio_5_feat, 5)[3], '\n')

print('Case 6 train Accuracy: %.5f' % predict_accuracy(cardio_6_feat, 5)[1])
print('Case 6 test Accuracy: %.5f' % predict_accuracy(cardio_6_feat, 5)[3], '\n')
```
```
>>
Case 1 train Accuracy: 0.72678
Case 1 test Accuracy: 0.72439 

Case 2 train Accuracy: 0.72246
Case 2 test Accuracy: 0.71824 

Case 3 train Accuracy: 0.72698
Case 3 test Accuracy: 0.72398 

Case 4 train Accuracy: 0.72795
Case 4 test Accuracy: 0.72439 

Case 5 train Accuracy: 0.72678
Case 5 test Accuracy: 0.72439 

Case 6 train Accuracy: 0.72277
Case 6 test Accuracy: 0.71866 
```  

ğŸ“Œ max_depth = None ì¸ ê²½ìš°ì— ë¹„í•´ train setê³¼ test set ì‚¬ì´ì˜ accuracy ì°¨ì´ê°€ í™•ì—°íˆ ì¤„ì–´ë“¬  

ğŸ“Œ Pruningì— ì˜í•´ ì˜¤ë²„í”¼íŒ…ì€ í•´ê²°ëœ ê²ƒìœ¼ë¡œ ë³´ì´ì§€ë§Œ, ì „ì²´ì ìœ¼ë¡œ accuracyê°€ ë†’ì€ ê°’ì€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ calssification algorithmì´ í•„ìš”í•¨.  

***  

## 2. PCA Data  

ğŸ PCA Data ì˜ ê²½ìš°ì—ëŠ” ìš°ì„  ë™ì¼í•˜ê²Œ targetì„ ë²”ì£¼í˜•ìœ¼ë¡œ ë°”ê¿”ì¤€ í›„, ì–´ëŠ ê¹Šì´ì—ì„œ ê²°ì • íŠ¸ë¦¬ê°€ ê°€ì¥ ì¢‹ì€ ê°’ì„ ë³´ì—¬ì£¼ëŠ”ì§€ ì‹œê°í™”ë¥¼ í•´ë³¼ ê²ƒì´ë‹¤. ì´ë ‡ê²Œ ì–»ì–´ë‚¸ ê°’ìœ¼ë¡œ accuracyë¥¼ ê³„ì‚°í•´ë³´ë„ë¡ í•˜ì.<br>  

```py
PCA_df.target = PCA_df['cardio'].copy()
PCA_df.target[PCA_df.target==0] = 'N'
PCA_df.target[PCA_df.target==1] = 'Y'
PCA_df.feat = PCA_df.drop(['cardio'], axis = 1).copy()

x_train_PCA, x_test_PCA, y_train_PCA, y_test_PCA = train_test_split(PCA_df.feat, PCA_df.target, test_size=0.2, random_state=1)

# Information Gain - entropy
clf_PCA = tree.DecisionTreeClassifier(criterion = "entropy", max_depth=6)  
clf_PCA = clf_PCA.fit(x_train_PCA, y_train_PCA)
```  

```py
# ê¹Šì´ì— ë”°ë¥¸ ì‹œê°í™”
accuracy_df = pd.DataFrame()
for i in range(1,20):
    a = tree.DecisionTreeClassifier(criterion = "entropy", max_depth=i)
    a = a.fit(x_train_PCA, y_train_PCA)  
    b = a.predict(x_test_PCA)
    accuracy_df =  accuracy_df.append(pd.DataFrame({'accuracy' : (accuracy_score(y_test_PCA, b)).round(5)}, index = [i]))
    
px.line(
    x=range(1,20),
    y=accuracy_df['accuracy'],
    labels={"x": "max_depth", "y": "Accuracy"}
)
```  
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/194764899-55867bd0-a8cf-43dd-b7b4-2cbd447deff8.png" width="1000" /></p>  

***  

### ğŸš©2.1. PCA ê²°ê³¼í•´ì„  

ğŸ ì•ì„  ì‹œê°í™” ê²°ê³¼ ê¹Šì´ê°€ 6 ì¼ë•Œ ê°€ì¥ ì¢‹ì€ accuracyë¥¼ ê°€ì¡Œê¸° ë•Œë¬¸ì— max_depth = 6 ì¸ ê²½ìš°ì˜ ê²°ê³¼ë¥¼ í•´ì„í•  ê²ƒì´ë‹¤.<br>  

```py
x_train_PCA, x_test_PCA, y_train_PCA, y_test_PCA = train_test_split(PCA_df.feat, PCA_df.target, test_size=0.2, random_state=1)
clf_PCA = tree.DecisionTreeClassifier(criterion = "entropy", max_depth=6)  # Information Gain - entropy
clf_PCA = clf_PCA.fit(x_train_PCA, y_train_PCA)

# max_depth = 6 ì¸ ê²½ìš°ì˜ train set / test set accuracy
y_pred_tr_PCA_test = clf_PCA.predict(x_test_PCA)
y_pred_tr_PCA_train = clf_PCA.predict(x_train_PCA)
print('PCA train Accuracy: %.5f' % accuracy_score(y_train_PCA, y_pred_tr_PCA_train))
print('PCA test Accuracy: %.5f' % accuracy_score(y_test_PCA, y_pred_tr_PCA_test))
```
```
>>
PCA train Accuracy: 0.72171
PCA test Accuracy: 0.71419
```  

ğŸ“Œ PCAë¥¼ ì§„í–‰í–ˆìŒì—ë„ ì•ì„œ ì¶”ì¶œí•œ attributeë¥¼ ê°€ì§€ê³  max_depthë¥¼ 5ë¡œ ì„¤ì •í•˜ì˜€ì„ ë•Œì˜ original data ê²°ê³¼ì™€ í° ì°¨ì´ê°€ ì—†ìŒ  

ğŸ“Œ ë‹¤ë¥¸ classification algorithmì´ í•„ìš”í•¨  

***  

ğŸ ì´ë ‡ê²Œ í•´ì„œ ê²°ì • íŠ¸ë¦¬ë¥¼ í†µí•œ ê° ë°ì´í„°ë“¤ì˜ accuracyë¥¼ êµ¬í•´ë³´ì•˜ë‹¤.  

ğŸ ê²°ë¡ ì ìœ¼ë¡œ, ê²°ì •íŠ¸ë¦¬ë§Œ ê°€ì§€ê³ ëŠ” ì´ ë°ì´í„°ì˜ targetì„ ì˜ˆì¸¡í•˜ê¸°ëŠ” ì–´ë ¤ì› ë‹¤. ë”°ë¼ì„œ ë‹¤ë¥¸ calssification ë°©ë²•ì„ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.  

ğŸ ë‹¤ìŒ ê¸€ì—ì„œëŠ” ì´ë ‡ê²Œ ë§Œë“  ê²°ì • íŠ¸ë¦¬ë¥¼ ì‹œê°í™”í•´ë³´ë„ë¡ í•˜ì.  

***

