# 2022-1 학기 데이터마이닝 프로젝트_(12)  

🐍 저번 글에서는 우리가 연관관계 분석을 통해 얻은 attribute set 5와 전처리만을 수행한 데이터, PCA 결과 만들어진 주성분 3가지 경우에 대해 결정 트리 모델을 만들었다. 이번 글에서는 결정 트리들이 모여 만들어지는 랜덤 포레스트를 통해 모델의 예측력을 시험해보도록 하자.<br>  

🐍 이렇게 만든 랜덤 포레스트에 대해서 ROC Curve와 Confusion Matrix를 만들어 각 모델들의 성능이 어떤지 직관적으로 비교해볼 것이다.  

***  

## 1. Attribute Set 5 [age, aphi, aplo, cholesterol, gluc, BMI, active] Random Forest  

📌 먼저 사용할 라이브러리는 아래와 같다.  

```py
# 데이터 셋을 train / test 로 분류해주는 라이브러리
from sklearn.model_selection import train_test_split 

# 랜덤포레스트를 위한 데이터 정규화 - StandardScaler 라이브러리
# 랜덤포레스트 생성 RandomForestClassifier 라이브러리
# acuuracy_score 라이브러리 : 정확도 계산 함수
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score 

# ROC Curve, Confusion Matrix, classification report 생성을 위한 라이브러리
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import (
    classification_report, confusion_matrix,
    ConfusionMatrixDisplay)
from enum import Enum
```  

📌 랜덤 포레스트를 구현하는 방법은 결정 트리와 크게 다르지 않다. 가지고 있는 데이터를 train set과 test set으로 나눠주고, 랜덤 포레스트 모듈을 사용하면 된다.  
📌 이때 우리가 정해줄 것은 포레스트에 위치할 각 트리들의 최대 깊이인데, 우리는 12일때 그 결과가 가장 좋게 나왔기 때문에 max_depth를 12로 설정했다.  

```py
# attribute set 5를 사용한 경우
cardio.target_out = cardio['cardio'].copy()
cardio.feat_out = cardio.drop(['cardio','gender','alco','smoke'], axis = 1).copy()

train_x_out, test_x_out, train_y_out, test_y_out = train_test_split(cardio.feat_out, cardio.target_out, test_size=0.3, random_state=0)

# 데이터 표준화 작업
sc = StandardScaler()
sc.fit(train_x_out)

# 표준화된 데이터셋
train_x_out_std = sc.transform(train_x_out)
test_x_out_std = sc.transform(test_x_out)

clf = RandomForestClassifier(random_state=0, max_depth = 12, n_estimators = 200)
clf.fit(train_x_out,train_y_out)

predict6 = clf.predict(train_x_out)
predict5 = clf.predict(test_x_out)

print("Train set accuracy : ", accuracy_score(train_y_out, predict6))
print("Test set accuracy : ", accuracy_score(test_y_out,predict5))
```  

```
>>
Train set accuracy :  0.7655592469545958
Test set accuracy :  0.7276485788113695
```  

***  

## 2. Original Data Random Forest  

```py
# original data의 모든 attribute를 사용한 경우 : case 1
cardio.target_all = cardio['cardio'].copy()
cardio.feat_all = cardio.drop(['cardio'], axis = 1).copy()

train_x_all, test_x_all, train_y_all, test_y_all = train_test_split(cardio.feat_all, cardio.target_all, test_size=0.3, random_state=0)

# 데이터 표준화 작업
sc = StandardScaler()
sc.fit(train_x_all)

# 표준화된 데이터셋
train_x_std_all = sc.transform(train_x_all)
test_x_std_all = sc.transform(test_x_all)

clf = RandomForestClassifier(random_state=0, max_depth = 12, n_estimators = 200)
clf.fit(train_x_all,train_y_all)

predict4 = clf.predict(train_x_all)
predict3 = clf.predict(test_x_all)

print("Train set accuracy : ", accuracy_score(train_y_all, predict4))
print("Test set accuracy : ", accuracy_score(test_y_all,predict3))  
```  
```
>>
Train set accuracy :  0.7690586932447397
Test set accuracy :  0.7299741602067183
```  

🚩 이렇게 original data에 대해 만들어진 랜덤 포레스트를 바탕으로 ROC Curve와 Confusion Matrix를 시각화할 것이다.<br>  

```py
# ROC Curve
# 전체 attribute를 사용한 경우의 ROC curve 출력
fpr_tr, tpr_tr, ths_tr = roc_curve(test_y_all, predict3)
auc_tr = auc(fpr_tr, tpr_tr)

fig = plt.figure(figsize = (8,4))
plt.subplot(121)
plt.plot(fpr_tr, tpr_tr, 
        lw=3, label='ROC curve (area = %0.2f)' % auc_tr)
plt.plot([0, 1], [0, 1], color='skyblue', lw=2,linestyle='--')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.legend(loc="lower right", prop={'size' : 10})
plt.title('validation set')
plt.show()  



# Confusion Matrix
# 전체 attribute를 사용한 경우의 confusion matrix 출력
class Diagnosis(Enum):
    No_Cardio = 0
    Cardio = 1    
    
cm = confusion_matrix(
    test_y_all,
    (predict3>.5).astype(np.int8),
#    normalize='true',
)
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=[d.name for d in Diagnosis],
)
disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1], cmap=plt.cm.Reds)
```  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/200122701-a182b5fe-3a5a-4689-8836-d2b4aa6a219d.jpg" width="320" /><img src="https://user-images.githubusercontent.com/65170165/200122702-d36ca164-99f3-48ab-a67f-1f5ad0b2b2b4.jpg" width="400" /></p><br>  


📌 original data에 대한 random forest의 결과를 해석하자면 아래와 같다.  
    - 결정 트리를 사용한 경우에 비해서 향상된 accuracy를 보여줌  
    - 하지만 좋은 결과를 얻었다고 하기엔 어려움  
    - 따라서 PCA를 통한 랜덤 포레스트도 수행 예정  
    
***  

## 3. PCA Dataframe Random Forest  

```py
PCA_df_target = PCA_df['cardio']
PCA_df_feat = PCA_df.drop(['cardio'],axis = 1)

train_x_PCA, test_x_PCA, train_y_PCA, test_y_PCA = train_test_split(PCA_df_feat, PCA_df_target, test_size=0.3, random_state=1)

clf = RandomForestClassifier(random_state=1)
clf.fit(train_x_PCA,train_y_PCA)

predict2 = clf.predict(train_x_PCA)
predict1 = clf.predict(test_x_PCA)

print("Train set accuracy : ", accuracy_score(train_y_PCA, predict2))
print("Test set accuracy : ", accuracy_score(test_y_PCA,predict1))
```  
```
>>
Train set accuracy :  0.9999114064230343
Test set accuracy :  0.7422739018087855
```  

🚩 ROC Curve와 Confusion Matrix를 만들어보자.<br>  

```py
# PCA DataFrame을 사용한 경우의 ROC curve 출력
fpr_tr, tpr_tr, ths_tr = roc_curve(test_y_PCA, predict1)
auc_tr = auc(fpr_tr, tpr_tr)

fig = plt.figure(figsize = (8,4))
plt.subplot(121)
plt.plot(fpr_tr, tpr_tr, 
        lw=3, label='ROC curve (area = %0.2f)' % auc_tr)
plt.plot([0, 1], [0, 1], color='skyblue', lw=2,linestyle='--')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.legend(loc="lower right", prop={'size' : 10})
plt.title('validation set')
plt.show()  


# PCA DataFrame을 사용한 경우의 confusion matrix 출력
class Diagnosis(Enum):
    No_Cardio = 0
    Cardio = 1    
    
cm = confusion_matrix(
    test_y_PCA,
    (predict1>.5).astype(np.int8),
#    normalize='true',
)
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=[d.name for d in Diagnosis],
)
disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1], cmap=plt.cm.Blues)
```  
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/200123108-50665335-36fc-4ca6-84fc-6b719631a4ec.jpg" width="302" /><img src="https://user-images.githubusercontent.com/65170165/200123109-948a905d-9f20-41cc-92f8-0ebcf66f3d7c.jpg" width="400" /></p><br>  

📌 PCA Dataframe을 사용해서 랜덤 포레스트를 돌린 결과는 아래와 같이 해석될 수 있다.  
    - 결정 트리를 사용한 결과에 비해 좋은 결과를 보여줌  
    - ROC Curve와 Confusion Matrix를 보면 Original Data를 사용한 경우보다 나은 예측력을 보여주는 것을 확인 가능함  
    - 하지만 train set의 accuracy와 test set의 accuracy 차이가 너무 크기 때문에 오버피팅이 일어났음을 알 수 있음  
    
***  
## 💡 4. 프로젝트 결론  

💡 데이터의 object가 많아 모델을 적용시켰을 때 accuracy가 좋을 것이라 예상했는데, 생각했던 것보다는 좋지 않았음<br>  

💡 이러한 결과들 중에서 가장 나은 성능을 보여준 경우를 뽑는다면 아래와 같음  
    - 🏆 전체 attribute를 사용한 경우의 raandom forest 모델  
    - 🏆 attribute set<5> : age, ap_hi, ap_lo, cholesterol, gluc, active, BMI 를 사용한 경우의 random forest 모델  
    
***  

🐍 이번 글을 끝으로 2022-1 에 수행한 데이터마이닝 프로젝트 <Cardio Vascular Data Mining> 정리를 끝냈다. 프로젝트가 끝이 나고 한참 후에 올린 글들이기 때문에 군데군데 미흡함이 있을 수 있다. 이렇게 정리하면서 나도 프로젝트 진행 과정에서는 찾지 못한 몇가지 오류들을 발견할 수 있었고, 새롭게 공부하는 느낌이 들어 좋았다. 데이터마이닝 이론을 언제 정리할 수 있을지는 모르겠지만, 이번 학기에 진행하는 프로젝트를 끝맺고 가급적이면 빨리 돌아오고 싶다😊😊.<br>  
    
🐍 아마 다음 글은 프로젝트 결과 레포트가 될 듯 하다. 프레젠테이션 자료도 올릴 수 있다면 올릴 예정이다!!  
    
***    
