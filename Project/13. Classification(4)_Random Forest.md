# 2022-1 학기 데이터마이닝 프로젝트_(12)  

🐍 저번 글에서는 우리가 연관관계 분석을 통해 얻은 attribute set 5와 전처리만을 수행한 데이터, PCA 결과 만들어진 주성분 3가지 경우에 대해 결정 트리 모델을 만들었다. 이번 글에서는 결정 트리들이 모여 만들어지는 랜덤 포레스트를 통해 모델의 예측력을 시험해보도록 하자.<br>  

🐍 이렇게 만든 랜덤 포레스트에 대해서 ROC Curve와 Confusion Matrix를 만들어 각 모델들의 성능이 어떤지 직관적으로 비교해볼 것이다.  

***  

## 1. Attribute Set 5 [age, aphi, aplo, cholesterol, gluc, BMI, active] Random Forest  

📌 먼저 사용할 라이브러리는 아래와 같다.  

```py
# 데이터 셋을 train / test 로 분류해주는 라이브러리
from sklearn.model_selection import train_test_split 

# 랜덤포레스트를 위한 데이터 정규화 - StandardScaler 라이브러리
# 랜덤포레스트 생성 RandomForestClassifier 라이브러리
# acuuracy_score 라이브러리 : 정확도 계산 함수
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score 

# ROC Curve, Confusion Matrix, classification report 생성을 위한 라이브러리
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import (
    classification_report, confusion_matrix,
    ConfusionMatrixDisplay)
from enum import Enum
```  

📌 랜덤 포레스트를 구현하는 방법은 결정 트리와 크게 다르지 않다. 가지고 있는 데이터를 train set과 test set으로 나눠주고, 랜덤 포레스트 모듈을 사용하면 된다.  
📌 이때 우리가 정해줄 것은 포레스트에 위치할 각 트리들의 최대 깊이인데, 우리는 12일때 그 결과가 가장 좋게 나왔기 때문에 max_depth를 12로 설정했다.  

```py
# attribute set 5를 사용한 경우
cardio.target_out = cardio['cardio'].copy()
cardio.feat_out = cardio.drop(['cardio','gender','alco','smoke'], axis = 1).copy()

train_x_out, test_x_out, train_y_out, test_y_out = train_test_split(cardio.feat_out, cardio.target_out, test_size=0.3, random_state=0)

# 데이터 표준화 작업
sc = StandardScaler()
sc.fit(train_x_out)

# 표준화된 데이터셋
train_x_out_std = sc.transform(train_x_out)
test_x_out_std = sc.transform(test_x_out)

clf = RandomForestClassifier(random_state=0, max_depth = 12, n_estimators = 200)
clf.fit(train_x_out,train_y_out)

predict6 = clf.predict(train_x_out)
predict5 = clf.predict(test_x_out)

print("Train set accuracy : ", accuracy_score(train_y_out, predict6))
print("Test set accuracy : ", accuracy_score(test_y_out,predict5))
```  

```
>>
Train set accuracy :  0.7655592469545958
Test set accuracy :  0.7276485788113695
```  

***  

## 2. Original Data Random Forest  

```py
# original data의 모든 attribute를 사용한 경우 : case 1
cardio.target_all = cardio['cardio'].copy()
cardio.feat_all = cardio.drop(['cardio'], axis = 1).copy()

train_x_all, test_x_all, train_y_all, test_y_all = train_test_split(cardio.feat_all, cardio.target_all, test_size=0.3, random_state=0)

# 데이터 표준화 작업
sc = StandardScaler()
sc.fit(train_x_all)

# 표준화된 데이터셋
train_x_std_all = sc.transform(train_x_all)
test_x_std_all = sc.transform(test_x_all)

clf = RandomForestClassifier(random_state=0, max_depth = 12, n_estimators = 200)
clf.fit(train_x_all,train_y_all)

predict4 = clf.predict(train_x_all)
predict3 = clf.predict(test_x_all)

print("Train set accuracy : ", accuracy_score(train_y_all, predict4))
print("Test set accuracy : ", accuracy_score(test_y_all,predict3))  
```  
```
>>
Train set accuracy :  0.7690586932447397
Test set accuracy :  0.7299741602067183
```  

🚩 이렇게 original data에 대해 만들어진 랜덤 포레스트를 바탕으로 ROC Curve와 Confusion Matrix를 시각화할 것이다.<br>  

```py
# ROC Curve
# 전체 attribute를 사용한 경우의 ROC curve 출력
fpr_tr, tpr_tr, ths_tr = roc_curve(test_y_all, predict3)
auc_tr = auc(fpr_tr, tpr_tr)

fig = plt.figure(figsize = (8,4))
plt.subplot(121)
plt.plot(fpr_tr, tpr_tr, 
        lw=3, label='ROC curve (area = %0.2f)' % auc_tr)
plt.plot([0, 1], [0, 1], color='skyblue', lw=2,linestyle='--')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.legend(loc="lower right", prop={'size' : 10})
plt.title('validation set')
plt.show()  



# Confusion Matrix
# 전체 attribute를 사용한 경우의 confusion matrix 출력
class Diagnosis(Enum):
    No_Cardio = 0
    Cardio = 1    
    
cm = confusion_matrix(
    test_y_all,
    (predict3>.5).astype(np.int8),
#    normalize='true',
)
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=[d.name for d in Diagnosis],
)
disp.plot(ax=plt.subplots(1, 1, facecolor='white')[1], cmap=plt.cm.Reds)
```  

